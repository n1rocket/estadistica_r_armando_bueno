{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tipos de error\n",
    "\n",
    "En estadística a veces se realizan hipótesis que pueden ser ciertas o falsas con cierto grado de confianza.\n",
    "\n",
    "Partimos de dos hipótesis:\n",
    "* Hipótesis nula, $H_0$: Es la hipótesis original, la que generalmente intentamos probar o desmentir.\n",
    "* Hipótesis alternativa, $H_1$: Es la hipótesis que tenemos que aceptar cuando $H_0$ se demuestra falsa.\n",
    "\n",
    "**Ejemplos de hipótesis:**\n",
    "\n",
    "Sobre la altura de las personas.\n",
    "* $H_0$: La media de la altura en España es 1.80m.\n",
    "* $H_1$: La media de la altura en España NO es 1.80m.\n",
    "\n",
    "Sobre el color de los perros:\n",
    "* $H_0$: Todos los perros son verdes.\n",
    "* $H_1$: Algún perro no es verde.\n",
    "\n",
    "Sobre pruebas médicas:\n",
    "* $H_0$: No está embarazada.\n",
    "* $H_1$: Sí está embarazada.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Si nuestro test estadístico dice que la hipótesis $H_1$ es cierta pero en realidad la que es cierta es la hipótesis $H_0$ estaremos cometiendo un error.\n",
    "El tipo de error depende de si nos hemos equivocado prediciendo $H_0$ o $H_1$.\n",
    "\n",
    "|.|$H_0$ cierta|$H_1$ cierta|\n",
    "|-|-|-|\n",
    "|Elegimos $H_0$| No hay error |Error tipo II, falso negativo|\n",
    "|Elegimos $H_1$| Error tipo I, falso positivo| No hay error |\n",
    "\n",
    "|.|$H_0$ cierta|$H_1$ cierta|\n",
    "|-|-|-|\n",
    "|Elegimos $H_0$| ![](pics/homerFat.jpg) No hay error | ![](pics/MargeError.png) Error tipo II, falso negativo |\n",
    "|Elegimos $H_1$| ![](pics/homerError.jpg) Error tipo I, falso positivo | ![](pics/MargePregnant.png) No hay error |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### p-valor\n",
    "\n",
    "En los tests estadísticos trataremos de confirmar o desmentir la hipótesis nula $H_0$ mediante un valor de confianza llamado p-valor.\n",
    "\n",
    "El p-valor es la probabilidad de que dado un modelo,la probabilidad de nuestros datos encajen en ese modelo. Es decir, es:\n",
    "\n",
    "\\\\[\n",
    "P(X \\mid \\theta)\n",
    "\\\\]\n",
    "\n",
    "No confundir con:\n",
    "\n",
    "\\\\[\n",
    "P(\\theta \\mid X)\n",
    "\\\\]\n",
    "\n",
    "Que es la probabilidad de que, dadas las muestras $X$, nuestro modelo sea $\\theta$.\n",
    "\n",
    "\n",
    "### Tipos de tests\n",
    "\n",
    "Se pueden realizar diferentes suposiciones sobre la distribución de probabilidad que siguen los datos en cuestión.\n",
    "\n",
    "* Las pruebas **paramétricas** son aquellas pruebas estadísticas que suponen que los datos siguen aproximadamente una distribución normal, entre otros supuestos (los ejemplos incluyen la prueba z, la prueba t y el ANOVA). Nota importante: el supuesto es que los datos de toda la población siguen una distribución normal, no los datos de la muestra con la que se trabaja.\n",
    "* Las pruebas **no paramétricas** son aquellas pruebas estadísticas que no asumen nada sobre la distribución que siguen los datos, y por ello también se conocen como pruebas sin distribución (ejemplos: Chi-cuadrado, U de Mann-Whitney). Las pruebas no paramétricas se basan en los rangos que tienen los distintos puntos de datos.\n",
    "\n",
    "Cada prueba paramétrica tiene un equivalente no paramétrico, lo que significa que para cada tipo de problema que tengas habrá una prueba en ambas categorías para ayudarte.\n",
    "\n",
    "\n",
    "### Dirección de la prueba\n",
    "\n",
    "Un test puede ser unilateral o bilateral, en función de los resultados que queramos medir\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando dos grupos de datos cuantitavos\n",
    "\n",
    "## Medias de dos grupos\n",
    "\n",
    "Tenemos dos grupos de datos y quieres saber si la media de ambos grupos es igual o no. Tenemos dos hipótesis:\n",
    "\\\\[H_0 : \\mu(X) = \\mu(Y) \\\\]\n",
    "\\\\[H_1 : \\mu(X) \\ne \\mu(Y) \\\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "#nx<-10\n",
    "#ny<-15\n",
    "nx<-5\n",
    "ny<-7\n",
    "\n",
    "X<-rnorm(nx,mean=7,sd=3)\n",
    "Y<-rnorm(ny,mean=5,sd=3)\n",
    "\n",
    "paste(\"Vector X:\",paste(round(X,2),collapse=\",\"))\n",
    "paste(\"Vector Y:\",paste(round(Y,2),collapse=\",\"))\n",
    "\n",
    "t_orig1<-mean(X)-mean(Y)\n",
    "t_orig2<-mean(Y)-mean(X)\n",
    "paste(\"La diferencia de medias es:\",t_orig1,\",\",t_orig2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cual es la probabilidad de que recombinando los valores de las variables X e Y la diferencia de las medias sea superior a la original?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_func <- function(x1, x2){\n",
    "    x<-c(x1,x2)\n",
    "    n<-length(x)\n",
    "    \n",
    "    idx1<-sample(1:n,length(x1))\n",
    "    #idx2<-setdiff(1:n,idx1)\n",
    "    list(x1=x[idx1],x2=x[-idx1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn<-c()\n",
    "num_out_X1_larger_X2<-0\n",
    "num_out_X2_larger_X1<-0\n",
    "total_trials<-10000\n",
    "\n",
    "for (i in 1:total_trials){\n",
    "    plist<-perm_func(X,Y)\n",
    "    x1<-plist$x1\n",
    "    x2<-plist$x2\n",
    "    \n",
    "    t<-mean(x1)-mean(x2)\n",
    "    mn<-c(mn,t)\n",
    "    \n",
    "    if (t>t_orig1){\n",
    "        num_out_X1_larger_X2<-num_out_X1_larger_X2+1\n",
    "    }\n",
    "    if (t< t_orig2){\n",
    "        num_out_X2_larger_X1<-num_out_X2_larger_X1+1\n",
    "    }\n",
    "}\n",
    "paste(\"La probabilidad de que por puro azar E[X] - E[Y] sea mayor de\",t_orig1,\":\",num_out_X1_larger_X2/total_trials)\n",
    "paste(\"La probabilidad de que por puro azar E[Y] - E[X] sea menor de\",t_orig2,\":\",num_out_X2_larger_X1/total_trials)\n",
    "paste(\"La probabilidad de que E[X] != E[Y]:\",(num_out_X2_larger_X1+num_out_X1_larger_X2)/total_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height=2,repr.plot.width=4, repr.plot.res = 300)\n",
    "library(ggplot2)\n",
    "ggplot(data.frame(x=mn),aes(x=x))+geom_density()+\n",
    "    stat_function(fun=dnorm,args = list(mean=0,sd=sd(mn)),color=\"red\")+\n",
    "    geom_vline(xintercept = t_orig1,color=\"blue\")+\n",
    "    geom_vline(xintercept = t_orig2,color=\"blue\")+\n",
    "  theme_linedraw()+xlab(\"mean(x1)-mean(x2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height=4,repr.plot.width=4, repr.plot.res = 300)\n",
    "\n",
    "qqnorm(mn,pch='.')\n",
    "qqline(mn,col=\"red\")\n",
    "abline(h = t_orig1,col=\"blue\")\n",
    "abline(h = t_orig2,col=\"blue\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test de student\n",
    "\n",
    "El origen de este test se remonta a 1908, a la fábrica de cerveza [Guiness](https://www.guinness-storehouse.com/content/pdf/archive-factsheets/general-history/wsgosset-and-students-t-test.pdf).\n",
    "\n",
    "El t-test es usado cuando tienes dos grupos de datos y quieres saber si la media de ambos grupos es igual o no. Tenemos dos hipótesis:\n",
    "\\\\[H_0 : \\mu(X) = \\mu(Y) \\\\]\n",
    "\\\\[H_1 : \\mu(X) \\ne \\mu(Y) \\\\]\n",
    "\n",
    "Empezamos con las siguientes suposiciones:\n",
    "1. Las muestras han sido seleccionas por muestreo aleatorio simple dentro de la población.\n",
    "2. Las poblaciones siguen una distribución normal. (sino usar test Wilcoxon-Mann-Whitney)\n",
    "3. Ambas poblaciones tienen la misma varianza. (sino usar test Welch)\n",
    "4. Las poblaciones no están correladas. (sino usar t-test emparejado)\n",
    "\n",
    "Primero calculamos la media y varianza de ambos grupos. El test para verificar si la hipótesis nula $H_0$ es cierta puede ser calculado como sigue:\n",
    "\n",
    "\\\\[ t=\\frac{E[X]-E[Y]}{s_p·\\sqrt{\\frac{1}{n_x}+\\frac{1}{n_y}}} \\\\]\n",
    "\n",
    "Donde $s_p$ es la desviación estandar compuesta, calculada como:\n",
    "\n",
    "\\\\[ s^2_p=\\frac{(n_x-1)Var[X]+(n_y-1)Var[Y]}{n_x+n_y-2} \\\\]\n",
    "\n",
    "Donde $n_x$ y $n_y$ son los números de muestras en cada uno de los grupos muestreados. El número de grados de libertad es \n",
    "$d.f.=n_x+n_y-2$. Podemos asumir que las dos varianzas son iguales si ambas pasan el test de varianza de Fisher(F-test).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp<-sqrt(((nx-1)*var(X)+(ny-1)*var(Y))/(nx+ny-2))\n",
    "t_orig<-(mean(X)-mean(Y))/(sp*sqrt(1/nx+1/ny))\n",
    "\n",
    "paste(\"El estimador t-estadístico es:\",t_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn<-c()\n",
    "num_out_X1_larger_X2<-0\n",
    "num_out_X2_larger_X1<-0\n",
    "total_trials<-10000\n",
    "for (i in 1:total_trials){\n",
    "    plist<-perm_func(X,Y)\n",
    "    x1<-plist$x1\n",
    "    x2<-plist$x2\n",
    "            \n",
    "    sp<-sqrt(((nx-1)*var(x1)+(ny-1)*var(x2))/(nx+ny-2))\n",
    "    \n",
    "    t<-(mean(x1)-mean(x2))/(sp*sqrt(1/nx+1/ny))\n",
    "    mn<-c(mn,t)\n",
    "    \n",
    "    if (t>t_orig){\n",
    "        num_out_X1_larger_X2<-num_out_X1_larger_X2+1\n",
    "    }\n",
    "    if (t< -1*t_orig){\n",
    "        num_out_X2_larger_X1<-num_out_X2_larger_X1+1\n",
    "    }\n",
    "}\n",
    "\n",
    "paste(\"La probabilidad de que por puro azar el estimador t sea mayor de\",t_orig,\":\",num_out_X1_larger_X2/total_trials)\n",
    "paste(\"La probabilidad de que por puro azar el estimador t sea menor de\",-1*t_orig,\":\",num_out_X2_larger_X1/total_trials)\n",
    "paste(\"La probabilidad de que E[X] != E[Y]:\",(num_out_X2_larger_X1+num_out_X1_larger_X2)/total_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height=2,repr.plot.width=6)\n",
    "library(ggplot2)\n",
    "ggplot(data.frame(x=mn),aes(x=x))+geom_density()+\n",
    "    stat_function(fun=dt,args = list(df = nx+ny-2),color=\"red\")+\n",
    "    stat_function(fun=dnorm,args = list(mean=0,sd=sd(mn)),color=\"green\")+\n",
    "\n",
    "    geom_vline(xintercept = t_orig,color=\"blue\")+\n",
    "    geom_vline(xintercept = -1*t_orig,color=\"blue\")+\n",
    "  theme_linedraw()+xlab(\"t=(mean(x1)-mean(x2))/(sp*sqrt(1/nx+1/ny))\")+\n",
    "   theme(axis.title.x = element_text(size = rel(0.8), angle = 00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height=4,repr.plot.width=4, repr.plot.res = 300)\n",
    "\n",
    "\n",
    "qqnorm(mn,pch='.')\n",
    "qqline(mn,col=\"red\")\n",
    "abline(h = t_orig,col=\"blue\")\n",
    "abline(h = -t_orig,col=\"blue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(x=qt(ppoints(length(mn)),df=nx+ny-2),y=mn,pch='.')\n",
    "qqline(mn,col=\"red\")\n",
    "abline(h = t_orig,col=\"blue\")\n",
    "abline(h = -t_orig,col=\"blue\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, estas la **diferencia de las medias normalizada** de estas variables siguen perfectamente una distribución t-student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "d.f.<-20\n",
    "\n",
    "loth<-qt(0.025,d.f.,lower.tail = T)\n",
    "upth<-qt(0.025,d.f.,lower.tail = F)\n",
    "\n",
    "paste(\"El margen que nos interesa está en el rango: [\",\n",
    "      round(loth,2),\",\",round(upth,2),\"]\")\n",
    "\n",
    "\n",
    "qsd009<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[x> loth  & x<upth  ]<-NA\n",
    "    out\n",
    "}\n",
    "options(repr.plot.height=3,repr.plot.width=6)\n",
    "xdf<-data.frame(z=c(-4,4))\n",
    "ggplot(xdf,aes(x=z))+stat_function(fun=dt,args = list(df = d.f.))+\n",
    "  stat_function(fun=qsd009, geom=\"area\",fill=\"red\")+\n",
    "  geom_text(x=3,y=0.1,size=4,label=paste0(\"t_cdf(\",round(upth,2),\")=0.975\"))+\n",
    "  geom_text(x=-3,y=0.1,size=4,label=paste0(\"t_cdf(\",round(loth,2),\")=0.025\"))+\n",
    "  theme_linedraw()\n",
    "options(repr.plot.height=7,repr.plot.width=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones en R\n",
    "\n",
    "Supongamos que tenemos dos variables aleatorias X e Y. Queremos saber si ambas proceden de la misma población. Una forma de saberlo es calcular la media de X e Y.\n",
    "A continuación calcular el test t-student y ver el p-valor. \n",
    "\n",
    "* Un valor muy **bajo**, por ejemplo inferior a 0.05, nos llevaría a rechazar la hipótesis nula $H_0$ y afirmar que las medias son tan diferentes que probablemente vendrán de poblaciones distintas.\n",
    "* Un p-valor **alto** nos indicaría que la hipótesis $H_0$ es posible que sea cierta.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "nx<-5\n",
    "ny<-7\n",
    "nx<-10\n",
    "ny<-15\n",
    "X<-rnorm(nx,mean=7,sd=3)\n",
    "paste(\"Media X:\",mean(X))\n",
    "Y<-rnorm(ny,mean=5,sd=3)\n",
    "paste(\"Media Y:\",mean(Y))\n",
    "data.frame(X=c(X,rep(NA,ny-nx)),Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp<-sqrt(((nx-1)*var(X)+(ny-1)*var(Y))/(nx+ny-2))\n",
    "t<-(mean(X)-mean(Y))/(sp*sqrt(1/nx+1/ny))\n",
    "paste(\"El estadístico t vale:\",t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que el estadístico t sigue una distribución t student, con lo cual, tenemos que averiguar cual es la probabilidad de que haya acabado con ese valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue<-(1-pt(abs(t),nx+ny-2))*2\n",
    "\n",
    "print(paste(\"El pvalor es\",pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el p-valor es bajo (menor de 0.05) significa que es bastante improbable que las medias de X e Y sean iguales. Por lo tanto en ese caso podríamos rechazar la hipótesis nula $H_0$. \n",
    "\n",
    "El mismo procedimiento lo podemos ejecutar usando la función *t.test*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test(X,Y,var.equal = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.f.<-nx+nx-2\n",
    "\n",
    "loth<-qt(0.025,d.f.,lower.tail = T)\n",
    "upth<-qt(0.025,d.f.,lower.tail = F)\n",
    "\n",
    "paste(\"El margen que nos llevaría a rechazar la hipótesis nula está fuera del rango: [\",\n",
    "      round(loth,2),\",\",round(upth,2),\"]\")\n",
    "\n",
    "\n",
    "qsd009<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[x> loth  & x<upth  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "qsdtest<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[x> -abs(t)  & x< abs(t)  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "\n",
    "options(repr.plot.height=2,repr.plot.width=6)\n",
    "xdf<-data.frame(z=c(-4,4))\n",
    "ggplot(xdf,aes(x=z))+stat_function(fun=dt,args = list(df = d.f.))+\n",
    "  stat_function(fun=qsd009, geom=\"area\",fill=\"red\",alpha=0.3)+\n",
    "  stat_function(fun=qsdtest, geom=\"area\",fill=\"yellow\",alpha=0.2)+\n",
    "  geom_text(x=3,y=0.1,size=4,label=paste0(\"t_cdf(\",round(upth,2),\")=0.975\"))+\n",
    "  geom_text(x=-3,y=0.1,size=4,label=paste0(\"t_cdf(\",round(loth,2),\")=0.025\"))+\n",
    "  geom_vline(xintercept = t,color=\"blue\")+\n",
    "  theme_linedraw()+xlab(\"t\")+ylab(\"prob\")\n",
    "options(repr.plot.height=2,repr.plot.width=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El p.valor es la integral de las dos áreas amarillas. Para rechazar la hipótesis nula el área debería ser la de las zona roja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test unilateral (izquierda)\n",
    "\n",
    "\\\\[H_0 : \\mu(X) >= \\mu(Y) \\\\]\n",
    "\\\\[H_1 : \\mu(X) < \\mu(Y) \\\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test(X,Y,var.equal = TRUE, alternative = \"less\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loth<-qt(0.05,d.f.,lower.tail = T)\n",
    "\n",
    "qsd009<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[x> loth  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "qsdtest<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[ x> t  ]<-NA\n",
    "    out\n",
    "}\n",
    "options(repr.plot.height=2,repr.plot.width=6)\n",
    "ggplot(xdf,aes(x=z))+stat_function(fun=dt,args = list(df = d.f.))+\n",
    "  stat_function(fun=qsd009, geom=\"area\",fill=\"red\",alpha=0.3)+\n",
    "  stat_function(fun=qsdtest, geom=\"area\",fill=\"yellow\",alpha=0.4)+\n",
    "  geom_vline(xintercept = t,color=\"blue\")+\n",
    "  theme_linedraw()\n",
    "options(repr.plot.height=7,repr.plot.width=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test unilateral (derecha)\n",
    "\n",
    "\\\\[H_0 : \\mu(X) <= \\mu(Y) \\\\]\n",
    "\\\\[H_1 : \\mu(X) > \\mu(Y) \\\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test(X,Y,var.equal = TRUE, alternative = \"greater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upth<-qt(0.05,d.f.,lower.tail = F)\n",
    "\n",
    "qsd009<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[ x<upth  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "qsdtest<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[ x< t  ]<-NA\n",
    "    out\n",
    "}\n",
    "options(repr.plot.height=2,repr.plot.width=6)\n",
    "ggplot(xdf,aes(x=z))+stat_function(fun=dt,args = list(df = d.f.))+\n",
    "  stat_function(fun=qsd009, geom=\"area\",fill=\"red\",alpha=0.3)+\n",
    "  stat_function(fun=qsdtest, geom=\"area\",fill=\"yellow\",alpha=0.4)+\n",
    "  geom_vline(xintercept = t,color=\"blue\")+\n",
    "  theme_linedraw()\n",
    "options(repr.plot.height=7,repr.plot.width=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-test de Welch\n",
    "\n",
    "Este test es usado cuando asumimos que las dos poblaciones no tienen porqué tener la misma varianza. El test estdístico es calculado así:\n",
    "\\\\[ t=\\frac{E[X]-E[Y]}{s_{\\bar{\\Delta}}} \\\\]\n",
    "\n",
    "donde\n",
    "\\\\[ s_{\\bar{\\Delta}}=\\sqrt{\\frac{Var[X]}{n_x}+\\frac{Var[Y]}{n_y}} \\\\]\n",
    "\n",
    "Y el número de grados de libertad es:\n",
    "\\\\[ d.f.= \\frac{\\left(\\frac{Var[X]}{n_x}+\\frac{Var[Y]}{n_y} \\right)^2}{\\frac{\\left( \\frac{Var[X]}{n_x} \\right)^2}{n_x-1} + \\frac{\\left( \\frac{Var[Y]}{n_y} \\right)^2}{n_y-1}} \\\\]\n",
    "\n",
    "igualmente lo calculamos sobre una t-student. Lo único que cambia es la forma de calcular los grados de libertad y la varianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones en R\n",
    "\n",
    "Supongamos que al igual que en el caso anterior tenemos dos variables aleatorias X, con 10 muestras, e Y, con 15 muestas. Queremos saber si ambas proceden de la misma población. Una forma de saberlo es calcular la media de X e Y sin asumir que ambos grupos tienen la misma varianza. A continuación calcular el test t-student y ver el p-valor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "X<-rnorm(nx,mean=7,sd=3)\n",
    "Y<-rnorm(ny,mean=10,sd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd<-sqrt(var(X)/nx+var(Y)/ny)\n",
    "t<-(mean(X)-mean(Y))/(sd)\n",
    "df<-(var(X)/nx+var(Y)/ny)^2/((var(X)/nx)^2/(nx-1)+(var(Y)/ny)^2/(ny-1))\n",
    "pvalue<-pt(t,df)*2\n",
    "\n",
    "print(paste(\"El pvalor es\",pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto se puede hacer en R con el comando *t.test*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso esl p-valor es realmente bajo, así que podemos rechazar la hipótesis nula y asumir que ambas medias no son iguales.\n",
    "\n",
    "\n",
    "![Imagen no cargada. Edita y borra la @ . Fuente: Pawn Stars](pics/pvalor.jpg )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Peso de los niños al nacer\n",
    "\n",
    "Este dataset contien información de bebes recien nacidos y sus padres. Nos vamos a centrar en si la madre era o no fumadora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwt<-read.csv(\"data/birthweight_reduced.csv\")\n",
    "bwt$smoker<-factor(bwt$smoker,labels = c(\"NO\",\"YES\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test bilateral**. Hipótesis:\n",
    "\n",
    "\\\\[H_0 : \\mu(X) = \\mu(Y) \\\\]\n",
    "\\\\[H_1 : \\mu(X) \\ne \\mu(Y) \\\\]\n",
    "\n",
    "* $H_0$ : El peso medio de los niños al nacer es igual en las madres fumadoras y no fumadoras.\n",
    "* $H_1$ : El peso medio de los niños al nacer es diferente (mayor o menor) en las madres fumadoras y no fumadoras.\n",
    "\n",
    "El pvalor es menor de 0.05, podemos tener indicios para rechazar la hipótesis nula y asumir que el peso de los niños al nacer va a ser diferente si las madres fuman o no.\n",
    "\n",
    "AVISO: No sabemos si los niños de las madres fumadores pesan más o menos, solo que pesan **distinto**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(bwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar t.test\n",
    "tw<-t.test(bwt$Birthweight[bwt$smoker==\"YES\"],bwt$Birthweight[bwt$smoker==\"NO\"])\n",
    "tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "d.f.<-tw$parameter\n",
    "t<-tw$statistic\n",
    "loth<-qt(0.025,d.f.,lower.tail = T)\n",
    "upth<-qt(0.025,d.f.,lower.tail = F)\n",
    "\n",
    "paste(\"El margen que nos llevaría a rechazar la hipótesis nula está fuera del rango: [\",\n",
    "      round(loth,2),\",\",round(upth,2),\"]\")\n",
    "\n",
    "\n",
    "qsd009<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[x> loth  & x<upth  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "qsdtest<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[x> -abs(t)  & x< abs(t)  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "\n",
    "options(repr.plot.height=2,repr.plot.width=6)\n",
    "xdf<-data.frame(z=c(-4,4))\n",
    "ggplot(xdf,aes(x=z))+stat_function(fun=dt,args = list(df = d.f.))+\n",
    "  stat_function(fun=qsd009, geom=\"area\",fill=\"red\",alpha=0.3)+\n",
    "  stat_function(fun=qsdtest, geom=\"area\",fill=\"yellow\",alpha=0.2)+\n",
    "  geom_text(x=3,y=0.1,size=4,label=paste0(\"t_cdf(\",round(upth,2),\")=0.975\"))+\n",
    "  geom_text(x=-3,y=0.1,size=4,label=paste0(\"t_cdf(\",round(loth,2),\")=0.025\"))+\n",
    "\n",
    "  geom_vline(xintercept = t,color=\"blue\")+\n",
    "\n",
    "  theme_linedraw()\n",
    "options(repr.plot.height=7,repr.plot.width=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test unilateral** (izquierdo). Hipótesis:\n",
    "\n",
    "\\\\[H_0 : \\mu(X) >= \\mu(Y) \\\\]\n",
    "\\\\[H_1 : \\mu(X) < \\mu(Y) \\\\]\n",
    "\n",
    "* $H_0$ : El peso medio de los niños al nacer es **mayor o igual** en las madres fumadoras que en las **no** fumadoras.\n",
    "* $H_1$ : El peso medio de los niños al nacer es **menor** en las madres fumadoras que en las **no** fumadoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw<-t.test(bwt$Birthweight[bwt$smoker==\"YES\"],bwt$Birthweight[bwt$smoker==\"NO\"],alternative = \"less\")\n",
    "tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El pvalor es menor de 0.05, podemos tener indicios para rechazar la hipótesis nula y asumir que el peso de los **niños de las madres fumadoras pesan menos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loth<-qt(0.05,d.f.,lower.tail = T)\n",
    "\n",
    "qsd009<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[x> loth  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "qsdtest<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[ x> t  ]<-NA\n",
    "    out\n",
    "}\n",
    "options(repr.plot.height=2,repr.plot.width=6)\n",
    "ggplot(xdf,aes(x=z))+stat_function(fun=dt,args = list(df = d.f.))+\n",
    "  stat_function(fun=qsd009, geom=\"area\",fill=\"red\",alpha=1)+\n",
    "  stat_function(fun=qsdtest, geom=\"area\",fill=\"yellow\",alpha=0.9)+\n",
    "  geom_vline(xintercept = t,color=\"blue\")+\n",
    "  theme_linedraw()\n",
    "options(repr.plot.height=7,repr.plot.width=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test unilateral** (derecho). Hipótesis:\n",
    "\n",
    "\\\\[H_0 : \\mu(X) <= \\mu(Y) \\\\]\n",
    "\\\\[H_1 : \\mu(X) > \\mu(Y) \\\\]\n",
    "\n",
    "* $H_0$ : El peso medio de los niños al nacer es **menor o igual** en las madres fumadoras que en las **no** fumadoras.\n",
    "* $H_1$ : El peso medio de los niños al nacer es **mayor** en las madres fumadoras que en las **no** fumadoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar t.test\n",
    "tw<-t.test(bwt$Birthweight[bwt$smoker==\"YES\"],bwt$Birthweight[bwt$smoker==\"NO\"],alternative = \"greater\")\n",
    "tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upth<-qt(0.05,d.f.,lower.tail = F)\n",
    "\n",
    "qsd009<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[ x<upth  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "qsdtest<-function(x){    \n",
    "    out<-dt(x,d.f.)\n",
    "    out[ x< t  ]<-NA\n",
    "    out\n",
    "}\n",
    "options(repr.plot.height=2,repr.plot.width=6)\n",
    "ggplot(xdf,aes(x=z))+stat_function(fun=dt,args = list(df = d.f.))+\n",
    "  stat_function(fun=qsd009, geom=\"area\",fill=\"red\",alpha=0.3)+\n",
    "  stat_function(fun=qsdtest, geom=\"area\",fill=\"yellow\",alpha=0.4)+\n",
    "  geom_vline(xintercept = t,color=\"blue\")+\n",
    "  theme_linedraw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso no podemos rechazar la hipótesis nula. El tabaco puede afectar o no al bebé, pero lo que parece más probable es que un bebé de madre fumadora no va a pesar más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test emparejado\n",
    "\n",
    "Este test es usado cuando hay **dos grupos** de datos los cuales están **correlados** y quieres saber si la media de ambos grupos es la misma o no. Esto puede ser usado por ejemplo para comprobar un estudio médico y queremos comprobar si los valores han cambiado antes y después del tratamiento. La hipóteis nula dice que la diferencia entre las dos medias es igual a $\\mu_0$\n",
    "\\\\[H_0 : \\mu(X) - \\mu(Y) = \\mu_0 \\\\]\n",
    "\\\\[H_1 : \\mu(X) -\\mu(Y) \\ne \\mu_0 \\\\]\n",
    "El test estadístico es calculado de la media y varianza de la diferencia de las dos muestras:\n",
    "\\\\[ t=\\frac{E[X-Y]-\\mu_0}{\\sqrt{var[X-Y]/n}}\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones en R\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo queremos comprobar si la diferencia en media entre las dos variables aleatorias X e Y es $\\mu_0=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n<-20\n",
    "X<-rnorm(n,mean=5,sd=4)\n",
    "Y<-X-rnorm(n,mean=3,sd=2)\n",
    "data.frame(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0<-2\n",
    "\n",
    "D<-X-Y\n",
    "t<-(mean(D)-mu0)/(sqrt(var(D)/n))\n",
    "pvalor<-(1-pt(t,n-1))*2\n",
    "print(paste(\"El pvalor es\",pvalor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O con la función *t.test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test(X,Y,mu=mu0,paired = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Colesterol\n",
    "\n",
    "Un estudio probó si el colesterol se redujo después de usar una cierta marca de margarina como parte de una dieta baja en grasas y baja en colesterol. Los sujetos consumieron en promedio 2,31g del ingrediente activo, stanol eastern, un día. Este conjunto de datos contiene información sobre 18 personas que usan margarina para reducir el colesterol en tres puntos de tiempo.\n",
    "Fuente: [www.statstutor.ac.uk](http://www.statstutor.ac.uk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl<-read.csv(\"data/stcp-dataset-cholesterol_des.csv\")\n",
    "\n",
    "head(chl)\n",
    "\n",
    "print(\"Para la margarina tipo A\")\n",
    "t.test(chl$Before[chl$Margarine==\"A\"],chl$After4weeks[chl$Margarine==\"A\"],paired=TRUE)\n",
    "\n",
    "print(\"Para la margarina tipo B\")\n",
    "t.test(chl$Before[chl$Margarine==\"B\"],chl$After4weeks[chl$Margarine==\"B\"],paired=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ambos casos el p-valor es bastante bajo, así que parece que los sujetos realmente bajaron su nivel de colesterol, muy posiblemente a causa de la margarina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilcoxon-Mann-Whitney test\n",
    "\n",
    "El U-test Mann-Whitney es usado para **comparar si dos variables independientes vienen de la misma distribución**. Funciona bajo las siguientes suposiciones:\n",
    "* Todas las observaciones de ambos grupos son independientes entre sí,\n",
    "* Las respuestas son ordinales (es decir, se puede decir al menos, de dos observaciones, caul es la mayor)\n",
    "* Bajo la hipótesis nula $H_0$, la probabilidad de que una observación de la población X supere una observación de la segunda población Y es igual a la probabilidad de que una observación de Y exceda una observación de X. \n",
    "* La hipótesis alternativa $H_1$ es la probabilidad de que una observación de la población X que excede una observación de la segunda población Y sea diferente de la probabilidad de que una observación de Y exceda una observación de X. La alternativa también puede establecerse en términos de una sola prueba a los lados, por ejemplo: P (X> Y)> P (Y> X).\n",
    "\n",
    "Las hipótesis son:\n",
    "\\\\[\n",
    "\\begin{split}\n",
    "H_0 : P(X > Y) = P(Y > X) \\\\\n",
    "H_1 :P(X > Y) \\ne P(Y > X)\n",
    "\\end{split}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones en R\n",
    "\n",
    "Esto puede ser calculado en R con la función $wilcox.test$. Vamos a comparar si existe o no diferencia en las millas por galón que puede recorrer cuando un coche tiene marchas manuales o automáticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(mtcars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars$mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars$am<-as.factor(mtcars$am) \n",
    "mtcars$am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    "\n",
    "ggplot(data=mtcars, aes(x=mpg, color=am))+geom_density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcox.test(mpg~am, data=mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos asumir que el consumo de gasolina de un coche (mtcars\\$mpg, miles per gallon), es dependiente de si el coche es o no automático (mtcars\\$am) porque el valor tan bajo del p-valor nos obliga a rechazar la hipótesis nula.\n",
    "La hipótesis nula es que ambas distribuciones son iguales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de varianza Fisher\n",
    "\n",
    "El test F es usado cuando se tienen **dos** grupos de datos procedentes de una distribución **normal** y se quiere saber si la **varianza** de ambos grupos es la misma. Esto significa que las variables son homocedasticas. La hipótesis con la que trabaja este test es :\n",
    "\\\\[H_0 : \\sigma(X) = \\sigma(Y) \\\\]\n",
    "\\\\[H_1 : \\sigma(X) \\ne \\sigma(Y) \\\\]\n",
    "\n",
    "El test estadítico se basa en el cociente de dos varianzas:\n",
    "\\\\[F=\\frac{Var[X]}{Var[Y]}\\\\]\n",
    "\n",
    "Esto sigue una distribución F con $n_x-1$ y $n_y-1$ grados de libertad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx<-10\n",
    "ny<-15\n",
    "X<-rnorm(nx,mean=7,sd=1)\n",
    "Y<-rnorm(ny,mean=7,sd=3)\n",
    "var.test(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de Bartlett\n",
    "\n",
    "El test de Bartlett es usado cuando se tienen **varios** grupos de datos procedentes de una distribución **cualquiera** y se quiere saber si la **varianza** de ambos grupos es la misma. Esto significa que las variables son homocedasticas. La hipótesis con la que trabaja este test es :\n",
    "\\\\[H_0 : \\sigma(X) = \\sigma(Y) \\\\]\n",
    "\\\\[H_1 : \\sigma(X) \\ne \\sigma(Y) \\\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n<- 20\n",
    "df<-data.frame(X=runif(n,min=-1,max=2),group=\"A\")\n",
    "df<-rbind(df,data.frame(X=runif(n,min=0,max=1),group=\"B\"))\n",
    "\n",
    "#head(df)\n",
    "\n",
    "bartlett.test(X~group, data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando normalidad (Shapiro)\n",
    "\n",
    "El Test de Shapiro–Wilk se usa para comprobar la normalidad de un conjunto de datos. \n",
    "Se plantea como hipótesis nula que una muestra X proviene de una población normalmente distribuida. Se considera como unos de los tests más fiables.\n",
    "\n",
    "En R se ejecuta llamando a shapiro.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro.test(rnorm(100,mean=10,sd=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJemplo shaprito uniforme\n",
    "shapiro.test(runif(100,min= -10, max=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el p-valor es muy bajo deberíamos rechazar la hipótesis nula. Es decir, la distribución no es normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Peso de niños al nacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "bwt<-read.csv(\"data/birthweight_reduced.csv\")\n",
    "bwt$smoker<-factor(bwt$smoker,labels = c(\"NO\",\"YES\"))\n",
    "\n",
    "paste(\"Las muestras de peso para madres fumadoras parecen seguir una gaussiana. pvalor:\",\n",
    "          shapiro.test(bwt$Birthweight[bwt$smoker==\"YES\"])$p.value)\n",
    "paste(\"Las muestras de peso para madres NO fumadoras parecen seguir una gaussiana. pvalor:\",\n",
    "          shapiro.test(bwt$Birthweight[bwt$smoker==\"NO\"])$p.value)\n",
    "\n",
    "\n",
    "tw<-t.test(bwt$Birthweight[bwt$smoker==\"YES\"],bwt$Birthweight[bwt$smoker==\"NO\"])\n",
    "print(\"Podemos aplicar un t-welch's test\")\n",
    "tw\n",
    "print(\"Parece que podría haber una diferencia estadística significativa en el peso del bebé si la madre fuma o no.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando distintos grupos de datos\n",
    "\n",
    "## ANOVA 1 variable\n",
    "\n",
    "Usamos ANOVA para comparar las medias de tres o más grupos de datos. Es decir, compara una variable dependiente (los datos de entrada) con una variable independiente  que tiene tres o más niveles (uno por cada grupo). Cada nivel identifica cada uno de los grupos de datos. La hipótesis nula afirma qeu todos los grupos tienen la misma media:\n",
    "\\\\[\n",
    "\\begin{split}\n",
    "H_0 : \\mu_1 = \\mu_2 = ... = \\mu_k \\\\\n",
    "H_1 : \\text{at leas one pair }\\mu_j\\ne \\mu_i \n",
    "\\end{split}\n",
    "\\\\]\n",
    "Estas hipótesis examinan si las muestras siguen la siguiente regresión lineal: $y_{ij}=\\mu_j+\\varepsilon_{ij}$, donde:\n",
    "* $y_{ij}$ es la variable dependiente, muestra i-ésima del grupo j.\n",
    "* $\\mu_j$ es la media real de grupo j, de la población total (desconocida pero estimable)\n",
    "* $\\varepsilon_{ij}$ son los errores resultantes del modelo\n",
    "* $\\bar{y}_j$ es la media muestral del grupo j\n",
    "* $k$ es el número de grupos\n",
    "* $n_j$ es el número de muestras del grupo j\n",
    "* $n=\\sum_{j=1}^{k}n_j$ es el número total de muestras\n",
    "\n",
    "El test-F omnibus test en anova de una variable es:\n",
    "\\\\[\n",
    "F=\\frac{\\sum_{j=1}^{k} n_j \\left ( \\bar{y_j}-\\bar{y} \\right )^2 / \\left ( k-1 \\right ) }{\\sum_{j=1}^{k} \\sum_{i=1}^{n_j} \\left ( y_{ij}-\\bar{y_j} \\right )^2 / \\left ( n-k \\right ) }=\\frac{\\text{Suma cuadrádica de residuos de cada grupo}}{\\text{Suma cuadrádica de residuos dentro de un grupo}}\n",
    "\\\\]\n",
    "\n",
    "\n",
    "\n",
    "ANOVA produce un test estadístico F, la relación de la varianza calculada entre los medios a la varianza dentro de las muestras. **Si los miembros del grupo provienen de poblaciones con los mismos valores medios, la varianza entre las medias del grupo debe ser menor que la varianza de las muestras**, siguiendo el teorema del límite central. Por lo tanto, una relación más alta implica que las muestras se tomaron de poblaciones con diferentes valores medios.\n",
    "\n",
    "Cuando solo hay dos medias para comparar la prueba t de Student (se debe usar la prueba t de Student), la prueba t y la prueba F son equivalentes; la relación entre ANOVA y t viene dada por $F = t^2$.\n",
    "\n",
    "\n",
    "\n",
    "Suposiciones de ANOVA:\n",
    "* La variable dependiente está distribuida sigue una distribución normal en cada grupo.\n",
    "* Hay homogeneidad de varianzas.\n",
    "* Las observaciones son independientes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones en R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "n1<-10; n2<-50; n3<-40\n",
    "m1<-18; m2<-15; m3<-15\n",
    "sd<-7\n",
    "\n",
    "a1<-rnorm(n1,mean=m1,sd=sd)\n",
    "a2<-rnorm(n2,mean=m2,sd=sd)\n",
    "a3<-rnorm(n3,mean=m3,sd=sd)\n",
    "\n",
    "ma1<-mean(a1)\n",
    "ma2<-mean(a2)\n",
    "ma3<-mean(a3)\n",
    "ma<-mean(c(a1,a2,a3))\n",
    "masq_between_group<-n1*(ma1-ma)^2+n2*(ma2-ma)^2+n3*(ma3-ma)^2\n",
    "df_between_group<-3-1\n",
    "mean_square_value_between_group<-masq_between_group/df_between_group\n",
    "\n",
    "masq_within_group<-sum((a1-ma1)^2)+sum((a2-ma2)^2)+sum((a3-ma3)^2)\n",
    "df_within_group<-n1-1+n2-1+n3-1\n",
    "mean_square_value_within_group<-masq_within_group/df_within_group\n",
    "\n",
    "F<-mean_square_value_between_group/mean_square_value_within_group\n",
    "F\n",
    "\n",
    "pvalue<-1-pf(F,df_between_group,df_within_group)\n",
    "print(paste(\"El pvalor es\",pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El p-valor es realmente bajo, por lo que podemos rechazar la hipótesis nula. Esto significa que no todos los grupos tienen la misma media. Se puede calcular con la función *aov*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- rbind(data.frame(value=a1,cl=\"1\"),data.frame(value=a2,cl=\"2\"),data.frame(value=a3,cl=\"3\"))\n",
    "df$cl <- as.factor(df$cl)\n",
    "head(df)\n",
    "str(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(aov( value ~ cl, data=df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O equivalentemente con la función *oneway.test* con el parámetro *var.equal=T*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneway.test( value ~ cl, data=df,var.equal = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diferente varianza\n",
    "\n",
    "Cuando los grupos no presentan la misma varianza, en lugar del test F se puede utilizar el test de Welch. Esto lo hace R con la función *oneway.test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneway.test( value ~ cl, data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diferentes distribuciones\n",
    "\n",
    "\n",
    "El test de Kruskal-Wallis se utiliza cuando en ANOVA no cumplimos la normalidad de los datos, cuando las muestras no vienen de una distribución gausiana.\n",
    "\n",
    "En R se utiliza la función *kruskal.test()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal.test( value ~ cl, data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados parecidos se pueden conseguir con una regresión lineal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(lm(value ~ cl, data=df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"Donde la media del primer grupo es la intersección con 0:\",mean(df$value[df$cl==1]))\n",
    "\n",
    "paste(\"Donde las medias del grupo2 se define en lm respecto al primer grupo:\",mean(df$value[df$cl==2])-mean(df$value[df$cl==1]))\n",
    "paste(\"Donde las medias del grupo3 se define en lm respecto al primer grupo:\",mean(df$value[df$cl==3])-mean(df$value[df$cl==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero simplemente hace test estadísticos por pares respecto al grupo más bajo. Es mejor usar ANOVA+Turkey test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(lm(value ~ cl, data=df[df$cl==2 | df$cl==3,]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de Tukey\n",
    "\n",
    "El test de Tukey también conocido como test HSD (honest significant difference), puede ser usado para encontrar las medias que son significativamente diferentes de cada uno de los grupos. El test de Tukey compara las medias de cada grupo respecto a las medias de cada otro grupo e indentifica cualquier diferencia entre las dos medias mayores que el error esperado. \n",
    "\n",
    "Es euivalente a un test de studnet pero con una pequeña diferenia. Cuando se hace el test Turkey se asume homogeneidad, así que la varianza es calculada con todas las muestras de todos los grupo. Cuando se hace un test de estudent la varianza de cada grupo es calculada independientemente lo cual produce un resultado menos robusto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TukeyHSD(aov( value ~ cl, data=df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto significa que el grupo 3 y 2 tienen una alta probabilidad de tener la misma media, y que la media del grupo 1 es diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tky<-TukeyHSD(aov( value ~ cl, data=df))\n",
    "tky.result<-data.frame(tky$cl)\n",
    "cn <-sort(unique(df$cl))\n",
    "resm <- matrix(NA, length(cn),length(cn))\n",
    "rownames(resm) <- cn\n",
    "colnames(resm) <- cn\n",
    "resm[lower.tri(resm) ] <- round(tky.result$p.adj,4)\n",
    "resm[upper.tri(resm) ] <- t(resm)[upper.tri(resm)] \n",
    "diag(resm) <- 1\n",
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "dfResm <- melt(resm)\n",
    "ggplot(dfResm, aes(x=Var1, y=Var2, fill=value))+\n",
    "  geom_tile(colour = \"black\")+\n",
    "  geom_text(aes(label=paste(round(value*100,0),\"%\")),size = 3) +\n",
    "  scale_fill_gradient(low = \"white\",high = \"steelblue\")+\n",
    "  ylab(\"Class\")+xlab(\"Class\")+theme_bw()+\n",
    "  theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: Efectividad de una dieta\n",
    "\n",
    "https://www.sheffield.ac.uk/polopoly_fs/1.570199!/file/stcp-Rdataset-Diet.csv\n",
    "\n",
    "Los datos contienen información de 76 personas que tomaron una de las tres dietas (1, 2 o 3). Además se aporta información extra como edad, género y altura. El objetivo del estudio es compara cual de las tres dietas era la mejor para perder peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet = read.csv(\"data/stcp-Rdataset-Diet.csv\",row.names=1)\n",
    "head(diet)\n",
    "diet$loss <- diet$pre.weight - diet$weight6weeks\n",
    "diet$Diet <- factor(diet$Diet)\n",
    "str(diet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "ggplot(diet, aes(y=loss, x=Diet, color=Diet))+geom_boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que los datos siguen una normal y que las varianzas son iguales con lo cual podemos **aplicar un test ANOVA**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (v in levels(diet$Diet)){\n",
    "    print(paste(\"Diet:\",v,\"pvalue,\",\n",
    "                shapiro.test(diet$loss[diet$Diet==v])$p.value))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el test ANOVA y vemos que efectivamente, hay una diferencia estadística significativa entre las diferentes dietas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneway.test(loss~Diet, data=diet, var.equal = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anovatest <- aov(loss~Diet, data=diet)\n",
    "summary(anovatest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tky<-TukeyHSD(anovatest)\n",
    "tky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggstatsplot)\n",
    "oneway.test(loss~Diet, data=diet)\n",
    "ggbetweenstats(\n",
    "  data = diet,\n",
    "  x = Diet,\n",
    "  y = loss,\n",
    "  xlab = \"Dieta\",\n",
    "  ylab = \"Perdida peso\",\n",
    "  plot.type = \"boxviolin\",\n",
    "  #type = \"robust\" \n",
    "  type = \"parametric\"  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tky.result<-data.frame(tky$Diet)\n",
    "cn <-sort(unique(diet$Diet))\n",
    "resm <- matrix(NA, length(cn),length(cn))\n",
    "rownames(resm) <- cn\n",
    "colnames(resm) <- cn\n",
    "resm[lower.tri(resm) ] <- round(tky.result$p.adj,4)\n",
    "resm[upper.tri(resm) ] <- t(resm)[upper.tri(resm)] \n",
    "diag(resm) <- 1\n",
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "dfResm <- melt(resm)\n",
    "ggplot(dfResm, aes(x=Var1, y=Var2, fill=value))+\n",
    "  geom_tile(colour = \"black\")+\n",
    "  geom_text(aes(label=paste(round(value*100,0),\"%\")),size = 3) +\n",
    "  scale_fill_gradient(low = \"white\",high = \"steelblue\")+\n",
    "  ylab(\"Class\")+xlab(\"Class\")+theme_bw()+\n",
    "  theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA dos variables independientes\n",
    "\n",
    "El ANOVA con dos variables independientes es una extensión del ANOVA de un factor en el que hay dos variables (factores) que interactúan con los datos. En este caso, los datos se dan en forma de matriz donde cada celda tendrá las muestras correspondientes a los dos factores dependientes, uno dado por el número de fila y otro por el número de columna.\n",
    "\n",
    "La hipótesis nula afirma que todos los grupos tienen la misma media:\n",
    "\\\\[\n",
    "\\begin{split}\n",
    "H_0 &: \\beta_1 = \\beta_2 = \\beta_3 = 0\\\\\n",
    "H_1 &: \\text{al menos un par }\\beta_j\\ne \\beta_i\n",
    "\\end{split}\n",
    "\\\\]\n",
    "Estas hipótesis examinan si las muestras siguen la siguiente regresión lineal de diferentes grupos: $y_{i}=\\beta_0+\\beta_1x_{i1}+\\beta_2x_{i2}+\\beta_3x_{i1}x_{i2}+\\varepsilon_{i}=\\widehat{y_i}+\\varepsilon_{i}$, donde:\n",
    "* $y_{i}$ es la variable dependiente, muestra i-ésima.\n",
    "* $\\beta_0$ es un coeficiente desconocido que tiene que ser estimado, es independiente de todas las variables.\n",
    "* $\\beta_1$ es un coeficiente desconocido que tiene que ser estimado para la primera variable independiente $x_{i1}$.\n",
    "* $\\beta_2$ es un coeficiente desconocido que tiene que ser estimado para la segunda variable independiente $x_{i2}$.\n",
    "* $\\beta_3$ es un coeficiente desconocido que tiene que ser estimado, refleja la interdepencia entre $x_{i1}$ y $x_{i2}$.\n",
    "* $x_{i1}$ es la primera variable dependiente asociada con la i-ésima muestra.\n",
    "* $x_{i2}$ es la segunda variable dependiente asociada con la i-ésima muestra.\n",
    "* $\\varepsilon_{ij}$ son los errores resultantes del modelo.\n",
    "* $\\widehat{y_i}$ es la estimación de la i-esima variable.\n",
    "* $k$ es el número de grupos\n",
    "* $n$ es el número total de muestras\n",
    "\n",
    "\n",
    "El test estadítico F es:\n",
    "\\\\[\n",
    "F=\\frac{\\sum_{j=1}^{n} \\left ( \\widehat{y_j}-\\bar{y} \\right )^2 / k }{\\sum_{j=1}^{k} \\sum_{i=1}^{n_j} \\left ( y_{ij}-\\widehat{y_j} \\right )^2 / \\left ( n-k-1 \\right ) }\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones en R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varId1<-c(1,2)\n",
    "varId2<-seq(0,5,length=4)\n",
    "var1<-c(rep(varId1,each=50))\n",
    "var2<-c(rep(varId2,length.out=length(var1)))\n",
    "var1\n",
    "var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y<-rnorm(length(var1),mean=0,sd=2)+var1+var2\n",
    "dfy<-data.frame(y,var1,var2)\n",
    "\n",
    "summary(aov( y ~ var1*var2, data=dfy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo dieta y género\n",
    "str(diet)\n",
    "diet$gender<-factor(diet$gender, labels=c(\"female\",\"male\"))\n",
    "summary(aov(loss~Diet+gender,data=diet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que afecta más a ciertas dietas en función del género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(aov(loss~Diet*gender,data=diet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tablas de contingencia\n",
    "\n",
    "Una tabla de contingencia es una tabla o matriz que muestar la frecuencia de ocurrencia de diferentes variables.\n",
    "\n",
    "|.|perro|gato|\n",
    "|-|-|-|\n",
    "|blanco|10|5|\n",
    "|negro|4|3|\n",
    "\n",
    "## Chi cuadrado\n",
    "\n",
    "El test chi cuadrado de Pearson puede ser usado como un test para validad la **independencia de datos categóricos**. Las hipótesis son:\n",
    "* La hipótesis nula $H_0$ es que las variables son independientes, no hay asociación estadística.\n",
    "* La hipótesis alternativa $H_1$ es que hay una relación estadístico o asociación entre variables.\n",
    "\n",
    "Este test hace las siguientes suposiciones:\n",
    "* Muestra obtenida por muestreo aleatorio.\n",
    "* La muestra es lo suficientemente grande.\n",
    "* El conteo en cada celda también tiene que ser estadísticamente significativo.\n",
    "* Las muestras se suponen independientes, los datos no pueden estar correlados.\n",
    "\n",
    "Este test se puede usar para las siguientes comparaciones:\n",
    "* **Test de homogeneidad** (goodnes: Compara si la distribución de datos es homogenea.\n",
    "* **Test de independencia**: Compara si observaciones de dos variables son independedientes una de la otra.\n",
    "* **Test de bondad**: para comparar si una distribución de frecuencias observdada difiere de una teórica.\n",
    "\n",
    "\n",
    "### Una variable\n",
    "\n",
    "En esta caso las observaciones consisten en valores de una única variable independiente (ej: un dado).\n",
    "El valor del test estadístico es:\n",
    "\n",
    "\\\\[\n",
    "\\chi^2 = \\sum_{i=1}^{n} \\frac{(O_i-E_i)^2}{E_i} = N \\sum_i^n \\frac{(O_i/N-p_i)^2}{p_i}\n",
    "\\\\]\n",
    "\n",
    "Donde:\n",
    "* $N$ es el número total de elementos observados.\n",
    "* $O_i$ es el número de elementos observados en la categoría *i*.\n",
    "* $E_i$ es el número de elementos esperados en la categoría *i*.\n",
    "* $p_i$ es la probabilidad esperada de encontrar un elemento en la categoría *i*. $$p_i=E_i/N$$\n",
    "* $n$ es el número de categoría en el estudio.\n",
    "\n",
    "Este estadístico es usado para calcular el p-valor comparando el valor del estadístico con la distribución chi-cuadrado donde el número de grados de libertad será $n-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones en R\n",
    "\n",
    "Por ejemplo, imaginemos que queremos comprobar si un dado de 4 lados es justo, es decir, si no está trucado. Tiramos 40 veces y apuntamos el número de veces. La tabla de frecuencias que aparece es:\n",
    "\n",
    "|**1**|**2**|**3**|**4**|\n",
    "|---|---|---|---|\n",
    "| 10| 7 | 9 | 14|\n",
    "\n",
    "Comprobar esto sería un **test de homogeneidad**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed<-c(10,7,9,14)\n",
    "observed<-c(10,7,9,0)\n",
    "\n",
    "N<-sum(observed)\n",
    "expected<-N/length(observed)\n",
    "test<-sum((observed-expected)^2/expected)\n",
    "\n",
    "pvalue<-1-pchisq(test,length(observed)-1)\n",
    "print(paste(\"El pvalor es\",pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El p-valor para aceptar la hipótesis nula es muy alto, así que podemos asumir $H_0$ y suponer que el dado probablemente sea justo. La función *chisq.test* de R puede ser usada para este propósito:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqt <- chisq.test(observed)\n",
    "cqt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.f.<-cqt$parameter\n",
    "t<-cqt$statistic\n",
    "loth<-qchisq(0.95,d.f.,lower.tail = T)\n",
    "\n",
    "\n",
    "qsd009<-function(x){    \n",
    "    out<-dchisq(x,d.f.)\n",
    "    out[x < loth  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "qsdtest<-function(x){    \n",
    "    out<-dchisq(x,d.f.)\n",
    "    out[ x <  t  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "chdf<-data.frame(z=c(-1,15))\n",
    "\n",
    "ggplot(chdf,aes(x=z))+stat_function(fun=dchisq,args = list(df = d.f.))+  \n",
    "  stat_function(fun=qsdtest, geom=\"area\",fill=\"yellow\",alpha=0.9)+\n",
    "  stat_function(fun=qsd009, geom=\"area\",fill=\"red\",alpha=1)+\n",
    "  geom_vline(xintercept = t,color=\"blue\")+\n",
    "  theme_linedraw()\n",
    "options(repr.plot.height=4,repr.plot.width=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dos variables\n",
    "\n",
    "En este caso, una observación consiste en los valores de dos variables. La hipótesis nula es que la ocurrencia de estos valores sea estadísticamente independiente. Cada observación está localizada en una celda de una matriz llamada tabla de contingencia. Si hay $r$ filas y $c$ columnas en la tabla, la frecuencia teórica por cada celda, bajo la hipótesis de independencia es:\n",
    "\n",
    "\\\\[\n",
    "    E_{i,j}=N p_i p_j\n",
    "\\\\]\n",
    "Donde:\n",
    "* p_i: Es la probabilidad de la fila $i$.\n",
    "* p_j: Es la probabilidad de la columna $j$.\n",
    "\n",
    "En este caso el valor del test estadístico es:\n",
    "\n",
    "\\\\[\n",
    "\\chi^2 = \\sum_i\\sum_j \\frac{(O_{i,j}-E_{i,j})^2}{E_{i,j}} \n",
    "\\\\]\n",
    "\n",
    "Y el número de grados de libertad es $$(r-1)(c-1)$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones en R\n",
    "\n",
    "Imaginemos que tenemos tres grupos de personas, A, B y C y les preguntamos si les gustan más los gatos o los perros. Obtendríamos la siguietne tabla:\n",
    "\n",
    "| . |**A**|**B**|**C**|\n",
    "|---|---|---|---|\n",
    "|cats | 100| 205 | 95  |\n",
    "|dogs | 203| 401 | 205 |\n",
    "\n",
    "Esto sería un **test de independencia** para ver si hay diferencia entre perros y gatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M <- as.table(rbind(c(100, 205, 95), c(203, 400, 205)))\n",
    "dimnames(M) <- list(animal = c(\"cats\", \"dogs\"), group = c(\"A\",\"B\", \"C\"))\n",
    "M\n",
    "chisq.test(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El elevado p-valor de 0.81 indica que podemos aceptar $H_0$, lo que significa que no hay diferencias en los grupos de personas que le gustan los perros y los gatos.\n",
    "\n",
    "Si modificamos una celda del grupo **C** y perros, obtenenemos un resultado diferente, en este caso tenemos que rechazar la hipótesis nula $H_0$ y asumir que hay diferencias entre perros y gatos para el siguiene grupo:\n",
    "\n",
    "|. |**A**|**B**|**C**|\n",
    "|---|---|---|---|\n",
    "|cats | 100| 205 | 95  |\n",
    "|dogs | 203| 401 | 275 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M <- as.table(rbind(c(100, 205, 95), \n",
    "                    c(203, 400, 275)))\n",
    "M\n",
    "cqt<- chisq.test(M)\n",
    "cqt$p.value\n",
    "cqt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.f.<-cqt$parameter\n",
    "t<-cqt$statistic\n",
    "loth<-qchisq(0.95,d.f.,lower.tail = T)\n",
    "\n",
    "\n",
    "qsd009<-function(x){    \n",
    "    out<-dchisq(x,d.f.)\n",
    "    out[x < loth  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "qsdtest<-function(x){    \n",
    "    out<-dchisq(x,d.f.)\n",
    "    out[ x < t  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "chdf<-data.frame(z=c(-1,15))\n",
    "\n",
    "ggplot(chdf,aes(x=z))+stat_function(fun=dchisq,args = list(df = d.f.))+  \n",
    "  stat_function(fun=qsdtest, geom=\"area\",fill=\"yellow\",alpha=0.9)+\n",
    "  stat_function(fun=qsd009, geom=\"area\",fill=\"red\",alpha=1)+\n",
    "  geom_vline(xintercept = t,color=\"blue\")+\n",
    "  theme_linedraw()\n",
    "options(repr.plot.height=4,repr.plot.width=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando distribuciones\n",
    "\n",
    "Es posible comparar si una distribución discreta sigue o no determinada función de probabilidad conocida. Para ello basta con comprobar como varía en una tabla\n",
    "\n",
    "En estos casos el valor $E_{i}$ es pasado como parámetro.\n",
    "\n",
    "\\\\[\n",
    "\\chi^2 = \\sum_i^n \\frac{(O_{i}-E_{i})^2}{E_{i}}=  N \\sum_i^n \\frac{(O_{i}-p_{i})^2}{p_{i}}\n",
    "\\\\]\n",
    "\n",
    "donde el número de grados de libertad es igual al número de columnas posibles menos el número de parámetros estimados:\n",
    "\\\\[\n",
    "d.f=n-p\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdata<-rpois(100, lambda = 7)\n",
    "rdata<-round(runif(100, min=0, max=20))\n",
    "\n",
    "tdata<-table(rdata)\n",
    "tdata\n",
    "#tdata<-table(factor(rdata, levels = as.character(0:max(rdata))))\n",
    "#tdata\n",
    "tdata<-c(as.numeric(tdata),0)\n",
    "tdata\n",
    "tdata<-tdata/sum(tdata)\n",
    "tdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs<-dpois(0:max(rdata), lambda = mean(rdata))\n",
    "probs<-c(probs,1-sum(probs))\n",
    "rbind(primary=tdata,reference=round(probs,4))\n",
    "\n",
    "chisq.test(x=tdata,  p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq.test(x=tdata,  p=probs, simulate.p.value=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrección de Yates por continuidad\n",
    "\n",
    "El uso de la distribución chi-cuadrado para interpretar el test estadístico requiere suponer que la probabilidad discreta de frecuencias binomiales observadas en la tabla se puede aproximar mediante la distribución chi-cuadrado continuo. Esta suposición no es del todo correcta e introduce algún error.\n",
    "\n",
    "Para reducir el error en la aproximación, Frank Yates sugirió una corrección para la continuidad que ajusta la fórmula del test chi-cuadrado. Consiste en restar como **máximo 0.5** de la diferencia entre cada valor **observado** y su  **esperado** en una tabla de contingencia de 2×2. Si la diferencia entre el valor observado y esperado fuera menor de 0.5, el numerador simplemente se iguala a 0, no se resta 0.5.  Esto reduce el valor de chi-cuadrado obtenido y por lo tanto aumenta su valor de p.\n",
    "\n",
    "\n",
    "\\\\[\n",
    "\\chi^2 = \\sum_i\\sum_j \\frac{(\\mid O_{i,j}-E_{i,j}\\mid-min(0.5,\\mid O_{i,j}-E_{i,j}\\mid))^2}{E_{i,j}}\n",
    "\\\\]\n",
    "\n",
    "En R se activa o desactiva con el parámetro *correct* dentro de la función *chisq.test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m <- matrix(c(7, 30, 15,40 ),nrow=2, byrow = F, dimnames = list(c(\"Star Trek\",\"Star Wars\"),c(\"Mujeres\",\"Hombres\")))\n",
    "m\n",
    "chisq.test(m)\n",
    "\n",
    "m <- matrix(c(7, 30, 15,40 ),nrow=2, byrow = F, dimnames = list(c(\"Star Trek\",\"Star Wars\"),c(\"Mujeres\",\"Hombres\")))\n",
    "m\n",
    "chisq.test(m,correct = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher\n",
    "\n",
    "El test exacto de Fisher siempre da el valor exacto del pvalor, a diferencia del test chi cuadrado el cual es solamente una aproximación, además funciona bien con muestras pequeñas. \n",
    "\n",
    "Una regla aproximada para decidir si usar la aproximáción del test chi-cuadrado o es necesario aplicar el test de fisher es cuando los valores de alguna de las celdas en una tabla de contingencia es menor de 5 o menor de 10 si solo hay dos columnas.\n",
    "\n",
    "El test es difícil de calcular a mano, pero fácil de calcular en R con la función *fisher.test*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M <- as.table(rbind(c(100, 205, 95), c(203, 401, 275)))\n",
    "fisher.test(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo: Dataset Titanic\n",
    "\n",
    "El Titanic se hundió en 1912 con la pérdida de la mayoría de sus pasajeros. Se pueden obtener detalles sobre 1309 pasajeros y tripulación a bordo del barco Titanic.\n",
    "Fuente: [www.statstutor.ac.uk](http://www.statstutor.ac.uk)\n",
    "\n",
    "Veamos si la nacionalidad del pasaje tiene que ver o no a la hora de saber si sobrevivieron o no:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tit<-read.csv(file = \"data/stcp-dataset-titanic_des.csv\")\n",
    "tit$Residence<-factor(tit$Residence,labels = c(\"American\",\"British\",\"Other\"))\n",
    "tit$survived<-factor(tit$survived,labels = c(\"Died\",\"Survived\"))\n",
    "tblres<-table(tit[,c(\"Residence\",\"survived\")])\n",
    "tblres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq.test(tblres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher.test(tblres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos tests nos obligan a rechazar la hipótesis nula: La nacionalidad no influye con la tasa de supervivencia.\n",
    "\n",
    "Así pues tenemos que concluir que si que existe una diferencia significativa en la probabilidad de sobrevivir dependiendo de la nacionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuciones estadísticas\n",
    "\n",
    "Podemos ver si una variable aleatoria sigue una distribución estadística con los denominados ajustes de bondad (Goodness of fit).\n",
    "\n",
    "Los pasos para tratar de encontrar una distribución estadísca que encaje son:\n",
    "\n",
    "1. Observar su distribución en frecuencias, calcular histograma (geom_histogram) o la probabilidad estimada (geom_density)\n",
    "1. Hacer una suposición sobre que distribución podría encajar. La estimación de los parámetros concretos se hará utilizando *Máxima versoimilitud*\n",
    "1. Utilizar un test estadístico para comprobar como de buena o mala es la distribución.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwt<-read.csv(\"data/birthweight_reduced.csv\")\n",
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    "\n",
    "bwtmn<-mean(bwt$Birthweight)\n",
    "bwtsd<-sd(bwt$Birthweight)\n",
    "\n",
    "library(ggplot2)\n",
    "ggplot(data=bwt,aes(x=Birthweight))+\n",
    "    stat_function(fun=dnorm,args = list(mean = bwtmn, sd=bwtsd), geom=\"area\",color=\"green\",fill=\"green\",alpha=0.1)+\n",
    "    geom_density(color=\"red\")+\n",
    "    theme_linedraw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Chi-cuadrado\n",
    "\n",
    "Ya vimos antes como utilizar este test para comparar una distribución de poisson. En esta sección veremos como repetir lo mismo para una distribución continua.\n",
    "\n",
    "El proceso es bastante sencillo simplemente hay que calcular el histograma de la función continua y calcular la probabilidad de que un punto aparezca en una de las barras usando como referencia la variable deseada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwt<-read.csv(\"data/birthweight_reduced.csv\")\n",
    "bwtmn<-mean(bwt$Birthweight)\n",
    "bwtsd<-sd(bwt$Birthweight)\n",
    "\n",
    "bwthist <- hist(bwt$Birthweight,breaks=14, right=FALSE,plot = FALSE)\n",
    "bwthist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressWarnings(library('zoo'))\n",
    "breaks<-bwthist$breaks\n",
    "breaks[1]<- -Inf\n",
    "breaks[length(breaks)]<- Inf\n",
    "\n",
    "breaks_cdf <- pnorm(breaks, mean=bwtmn, sd=bwtsd)\n",
    "ref.probs <- rollapply(data=breaks_cdf, width=2, function(x) x[2]-x[1])\n",
    "ref.probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rbind(test=round(bwthist$density,4),reference=round(ref.probs,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq.test(bwthist$density, p=ref.probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Kolmogorov-Smirnov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compara la probabilidad acumulada de una distribución con una de referencia.\n",
    "\n",
    "La función acumulativa empírica se puede representar como:\n",
    "\\\\[\n",
    "F_{n}(x)={1 \\over n}\\sum _{i=1}^{n}\\left\\{{\\begin{matrix}1&\\mathrm {si} \\ y_{i}\\leq x,\\\\0&\\text{otro caso} .\\end{matrix}}\\right.\n",
    "\\\\]\n",
    "El estadístico de Kolmogorov-Smirnov es:\n",
    "\\\\[\n",
    "D_{n}=\\sup _{x}|F_{n}(x)-F(x)|\n",
    "\\\\]\n",
    "\n",
    "La función acumulativa de la distribución de Komogorov es:\n",
    "\\\\[\n",
    "{Pr} (K\\leq x)=1-2\\sum _{k=1}^{\\infty }(-1)^{k-1}e^{-2k^{2}x^{2}}={\\frac {\\sqrt {2\\pi }}{x}}\\sum _{k=1}^{\\infty }e^{-(2k-1)^{2}\\pi ^{2}/(8x^{2})}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrnd<-runif(100,min=-5,5)\n",
    "x<-sort(myrnd)\n",
    "cdf1<-cumsum(abs(x))/sum(abs(myrnd))\n",
    "cdf2<-pnorm(x,mean=0,sd=sqrt(100/12))\n",
    "idx<-which.max(abs(cdf1-cdf2))\n",
    "\n",
    "ggplot(data=data.frame(x=x,test=cdf1,reference=cdf2),aes(x=x))+\n",
    "    geom_step(aes(y=cdf1),col=\"red\")+\n",
    "    geom_line(aes(y=cdf2),col=\"blue\")+\n",
    "    geom_segment(x=x[idx],y=cdf1[idx],xend=x[idx],yend=cdf2[idx])+\n",
    "    theme_light()\n",
    "\n",
    "\n",
    "paste(\"F estadístico: \",abs(cdf1[idx]-cdf2[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En R se puede probar con la función *ks.test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.test(myrnd,\"pnorm\",0,sqrt(100/12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede utilizar para comparar entre dos distribuciones cualquiera para comprobar si son iguales o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.test(myrnd, rnorm(length(myrnd),0,sqrt(100/12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si volvemos al ejemplo del peso de los bebes, podemos ejecutar este test para ver si sigue una gaussiana o no:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    "ggplot(data=bwt,aes(x=Birthweight))+\n",
    "    stat_ecdf()+\n",
    "    stat_function(fun=pnorm,args =  list(mean = bwtmn, sd=bwtsd),col=\"red\")+\n",
    "    theme_linedraw()+xlab(\"Peso\")+ylab(\"prob acumulada\")+ggtitle(\"Peso de un bebé al nacer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.test(bwt$Birthweight,\"pnorm\",bwtmn,bwtsd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El K-S test de R se queja de que hay datos duplicados. Algo que no debería ocurrir cuando tenemos datos que siguen una distribución realmente aleatoria.\n",
    "\n",
    "Tampoco se aconseja calcular los parámetros estadísticos como media y varianza de las muestras en si.\n",
    "\n",
    "Como alternativa se puede usar wilcox.test() o chisq.test(). También existe una alternativa y es usar el paquete KScorrect que aplica una corrección al test K-S para poder utilizar los parámetros estadísticos obtenidos de la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para instalar el siguiente paquete en la máquina virtual de Vagrant descomentar las siguientes lineas:\n",
    "#\n",
    "#dir.create(file.path(\"/home/vagrant/R/x86_64-pc-linux-gnu-library/3.2\"),recursive = T)\n",
    "#install.packages(c('KScorrect'), lib=\"~/R/x86_64-pc-linux-gnu-library/3.2\", repos='https://cran.rstudio.com/',verbose=F)\n",
    "library(\"KScorrect\",lib.loc = \"/home/vagrant/R/x86_64-pc-linux-gnu-library/3.2\")\n",
    "lc<-LcKS(bwt$Birthweight, cdf=\"plnorm\")\n",
    "lc$p.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máxima verosimilitud (MLE)\n",
    "\n",
    "La Máxima verosimilitud (Maximum likelihood estimation) es un método para estimar los parámetros de un modelo estadístico dadas ciertas observaciones del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "Imagínate que tienes una báscula poco precisa y la utilizas para medir el peso de un periquito adulto.\n",
    "Te salen 3 medidas: 50g, 42g, 47g.\n",
    "\n",
    "![](pics/pollo.jpg)\n",
    " \n",
    "\n",
    "¿Cual es la media?\n",
    "Si suponemos que la media son 40g y la desviación típica 10g tendríamos la siguiente gráfica, ¿cual sería la probabilidad de obtener esas medidas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "weights<-c(50,42,47)\n",
    "\n",
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    "xdf<-data.frame(z=c(0,70))\n",
    "ggplot(xdf,aes(x=z))+stat_function(fun=dnorm,args = list(mean = 40, sd =10))+\n",
    "  geom_vline(xintercept = weights[1],color=\"blue\")+\n",
    "  geom_vline(xintercept = weights[2],color=\"blue\")+\n",
    "  geom_vline(xintercept = weights[3],color=\"blue\")+\n",
    "  ylab(\"probabilidad\")+xlab(\"Peso [g]\")+\n",
    "  theme_linedraw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad a posteriori condicionada a una gaussiana de media $\\mu=40$ y desviación típida $\\sigma=10$ se calcula como:\n",
    "\\\\[\n",
    "\\begin{split}\n",
    "    P(X \\mid \\theta) &= P(X \\mid \\mu,\\sigma)  = \\prod_{i=1}^N P(x_i \\mid \\mu,\\sigma) \\\\ \n",
    "    P(X \\mid \\mu,\\sigma) &= \\prod_{i=1}^N \\frac {1}{\\sqrt {2\\pi \\sigma ^{2}}}\\;e^{-{\\frac {(x_i-\\mu )^{2}}{2\\sigma ^{2}}}}\n",
    "\\end{split}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnkg=40\n",
    "sdkg=10\n",
    "prob<-dnorm(weights[1],mean=mnkg,sd=sdkg)*\n",
    "      dnorm(weights[2],mean=mnkg,sd=sdkg)*\n",
    "      dnorm(weights[3],mean=mnkg,sd=sdkg)\n",
    "paste0(\"La probabilidad es: P(X|\",mnkg,\",\",sdkg,\")=\",round(prob,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué ocurriría si tuvieramos una gaussiana de media 36? ¿cual sería la probabilidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnkg=36\n",
    "sdkg=10\n",
    "prob<-dnorm(weights[1],mean=mnkg,sd=sdkg)*\n",
    "      dnorm(weights[2],mean=mnkg,sd=sdkg)*\n",
    "      dnorm(weights[3],mean=mnkg,sd=sdkg)\n",
    "paste0(\"La probabilidad es: P(X|\",mnkg,\",\",sdkg,\")=\",round(prob,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cual es el valor óptimo de $\\theta=\\{\\mu,\\sigma\\}$ que maximiza la probabilidad?\n",
    "\n",
    "La probabilidad para el vector $X$ de $n$ observaciones viene dada por:\n",
    "\\\\[\n",
    "\\mathcal {L}(\\theta)=P(X_1=x_1,X_2=x_2,\\ldots,X_n=x_n)=f(x_1;\\theta)\\cdot f(x_2;\\theta)\\cdots f(x_n;\\theta)=\\prod\\limits_{i=1}^n f(x_i;\\theta)\n",
    "\\\\]\n",
    "\n",
    "Es el estimador de máxima verosimilitud, que se calcula como: \n",
    "\\\\[\n",
    "\\hat {\\theta }\\in \\{{\\underset {\\theta \\in \\Theta }{\\operatorname {arg\\,max} }}\\ {\\mathcal {L}}(\\theta \\,;x)\\}\n",
    "\\\\]\n",
    "\n",
    "Maximizar $\\mathcal {L}$ equivale a maximizar su logaritmo. Muchas veces es mejor trabajar con logaritmos, sobretodo con funciones de probabilidad basadas en exponenciales:\n",
    "\\\\[\n",
    "{\\displaystyle \\ell (\\theta \\,;x)=\\ln {\\mathcal {L}}(\\theta \\,;x),}\n",
    "\\\\]\n",
    "\n",
    "Su máximo se puede obtener derivando respecto a $\\theta$ e igualando a cero:\n",
    "\n",
    "\\\\[\n",
    " \\frac {\\partial }{\\partial \\theta }\\ln {\\Big (}{\\mathcal {L}}(\\theta ){\\Big )}=0\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo MLE de gaussiana:\n",
    "\n",
    "La función de distribución es:\n",
    "\\\\[\n",
    "f(x\\mid \\mu ,\\sigma )={\\frac {1}{{\\sqrt {2\\pi \\sigma ^{2}}}\\ }}\\exp {\\left(-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}}\\right)},\n",
    "\\\\]\n",
    "\n",
    "La probabilidad de de tener una muestra de $n$ muestras independientes identicamente distribuidas de forma aleatoria es: \n",
    "\\\\[\n",
    "\\mathcal {L}(\\theta)=\\mathcal {L}(\\mu ,\\sigma ) =f(x_{1},\\ldots ,x_{n}\\mid \\mu ,\\sigma ^{2})=\\prod _{i=1}^{n}f(x_{i}\\mid \\mu ,\\sigma ^{2})=\\left({\\frac {1}{2\\pi \\sigma ^{2}}}\\right)^{n/2}\\exp \\left(-{\\frac {\\sum _{i=1}^{n}(x_{i}-\\mu )^{2}}{2\\sigma ^{2}}}\\right),\n",
    "\\\\]\n",
    "\n",
    "Para simplificar pasamos a logaritmos:\n",
    "\\\\[\n",
    "\\ln {\\Big (}{\\mathcal {L}}(\\mu ,\\sigma ){\\Big )}=-{\\frac {\\,n\\,}{2}}\\ln(2\\pi \\sigma ^{2})-{\\frac {1}{2\\sigma ^{2}}}\\sum _{i=1}^{n}(\\,x_{i}-\\mu \\,)^{2}\n",
    "\\\\]\n",
    "\n",
    "Calculamos el estimador de máxima verosimilitud para la media:\n",
    "\\\\[\n",
    "{\\begin{aligned}0&={\\frac {\\partial }{\\partial \\mu }}\\log {\\Big (}{\\mathcal {L}}(\\mu ,\\sigma ){\\Big )}=0-{\\frac {\\;-2\\!n({\\bar {x}}-\\mu )\\;}{2\\sigma ^{2}}}.\\end{aligned}}\n",
    "\\\\]\n",
    "El resultado es:\n",
    "\\\\[\n",
    "{\\hat {\\mu }}={\\bar {x}}=\\sum _{i=1}^{n}{\\frac {\\,x_{i}\\,}{n}}\n",
    "\\\\]\n",
    "Si repetimos el proceso para la desviación típica obtendríamos:\n",
    "\\\\[\n",
    "\\widehat {\\sigma }^{2}={\\frac {1}{n}}\\sum _{i=1}^{n}(x_{i}-\\mu )^{2}\n",
    "\\\\]\n",
    "**AVISO**: El MLE no nos devuelve el estimador sesgado de la varianza porque $\\mu \\neq \\hat {\\mu }$. Si en la equación de $\\widehat {\\sigma }^{2}$ metemos la de $\\hat {\\mu }$. Obtenemos:\n",
    "\\\\[\n",
    "\\operatorname {E} {\\big [}\\;{\\widehat {\\sigma }}^{2}\\;{\\big ]}={\\frac {\\,n-1\\,}{n}}\\sigma ^{2}.\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sapply(weights,function(xi) dnorm(xi,mean=mnkg,sd=sdkg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnkg=36\n",
    "#sdkg=10\n",
    "\n",
    "l<-function(theta){\n",
    "    mnkg=theta[1]\n",
    "    sdkg=theta[2]\n",
    "    -prod(sapply(weights,function(xi) dnorm(xi,mean=mnkg,sd=sdkg)))\n",
    "}\n",
    "                \n",
    "o<-optim(c(50,10), l)\n",
    "                \n",
    "paste(\"La media óptima calculada mediante MLE es:\",o$par[1])\n",
    "paste(\"La media estimada es:\",mean(weights))\n",
    "                 \n",
    "paste(\"La desviación típica óptima calculada mediante MLE es:\",o$par[2])\n",
    "paste(\"La desviación típica estimada es:\",sd(weights))                 \n",
    "o                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Ejemplo MLE de bernoulli:\n",
    "\n",
    "La formula de la distribución de probabilidad de una Bernuilli es:\n",
    "\\\\[\n",
    "f(k;p)=p^k(1-p)^{1-k}\n",
    "\\\\]\n",
    "\n",
    "La probabilidad de de tener una muestra de $n$ muestras independientes identicamente distribuidas de forma aleatoria es: \n",
    "\\\\[\n",
    "\\mathcal {L}(\\theta)=\\mathcal {L}(p ) =f(x_{1},\\ldots ,x_{n}\\mid \\mu ,\\sigma ^{2})=\\prod _{i=1}^{n}f(x_{i}\\mid \\mu ,\\sigma ^{2})=p^{\\sum x_i} (1-p)^{n-\\sum x_i}\n",
    "\\\\]\n",
    "\n",
    "Para simplificar pasamos a logaritmos:\n",
    "\\\\[\n",
    "\\ln {\\Big (}{\\mathcal {L}}(p ){\\Big )}=\\Big(\\sum x_i\\Big)\\ln(p)+\\Big(n-\\sum x_i\\Big)\\ln(1-p)\n",
    "\\\\]\n",
    "\n",
    "Calculamos el estimador de máxima verosimilitud para calcular $p$:\n",
    "\\\\[\n",
    "0={\\frac {\\partial }{\\partial p }}\\log {\\Big (}{\\mathcal {L}}(p ){\\Big )}=\\frac{\\Big(\\sum x_i\\Big)}{p}+\\frac{\\Big(n-\\sum x_i\\Big)}{(1-p)}\n",
    "\\\\]\n",
    "El resultado es:\n",
    "\\\\[\n",
    "{\\hat {p }}=\\sum _{i=1}^{n}{\\frac {\\,x_{i}\\,}{n}}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X<-rbinom(50,size=1,p=0.3)\n",
    "\n",
    "l<-function(p){\n",
    "    -prod(sapply(X,function(xi) p^xi*(1-p)^(1-xi)))\n",
    "}\n",
    "                \n",
    "o<-optimize(l,c(0,1))\n",
    "                \n",
    "paste(\"La media óptima calculada mediante MLE es:\",o$minimum)\n",
    "paste(\"La media estimada es:\",mean(X))\n",
    "                 \n",
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum a Posteriori (MAP) e inferencia Bayesiana\n",
    "\n",
    "Imaginemos que tenemos información adicional, como por ejemplo la siguiente tabla de la [Wikipedia](https://en.wikipedia.org/wiki/Budgerigar):\n",
    "```\n",
    "Wild budgerigars average 18 cm (7 in) long, weigh 30–40 grams (1.1–1.4 oz), 30 cm (12 in) in wingspan, and display a light green body colour (abdomen and rumps), while their mantles (back and wing coverts) display pitch-black mantle markings (blackish in fledgelings and immatures) edged in clear yellow undulations. \n",
    "```\n",
    "Ahí vemos que el peso medio de los periquitos adultos es de unos 35g.\n",
    "\n",
    "¿Cómo podemos saber la varianza?\n",
    "\n",
    "Suponemos que el margen de 30-40 gramos corresponde con el intervalo de confianza del 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_sd<-function(x,p,weight){    \n",
    "    (qnorm(p,mean=35,sd=x)-weight)^2\n",
    "}\n",
    "o<-optimize(calc_sd,c(0,10),p=0.9,weight=40)\n",
    "paste(\"La desviación típica calculada con el percentil 90 es:\",o$minimum)\n",
    "\n",
    "o<-optimize(calc_sd,c(0,10),p=0.1,weight=30)\n",
    "paste(\"La desviación típica calculada con el percentil 10 es:\",o$minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "\n",
    "sd_est <- 3.901\n",
    "\n",
    "loth<-qnorm(0.1,lower.tail = T, mean=35, sd=sd_est)\n",
    "upth<-qnorm(0.1,lower.tail = F, mean=35, sd=sd_est)\n",
    "\n",
    "paste(\"El margen que nos interesa está en el rango: [\",\n",
    "      round(loth,2),\",\",round(upth,2),\"]\")\n",
    "\n",
    "\n",
    "qsd009<-function(x){    \n",
    "    out<-dnorm(x, mean=35, sd=sd_est)    \n",
    "    out[x<loth  | x>upth  ]<-NA\n",
    "    out\n",
    "}\n",
    "\n",
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    "xdf<-data.frame(z=c(20,50))\n",
    "ggplot(xdf,aes(x=z))+stat_function(fun=dnorm, args=list(\"mean\"=35,\"sd\"=sd_est))+\n",
    "  stat_function(fun=qsd009, geom=\"area\",fill=\"red\", alpha=0.5)+\n",
    "  geom_text(x=44,y=0.047,size=4,label=paste0(\"n_cdf(\",round(upth,2),\")=0.9\"))+\n",
    "  geom_text(x=26,y=0.047,size=4,label=paste0(\"n_cdf(\",round(loth,2),\")=0.1\"))+\n",
    "  theme_linedraw()\n",
    "options(repr.plot.height=7,repr.plot.width=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para redondear, supongamos que el conocimiento que tenemos a priori es que los periquitos tienen un peso medio de 35g con una desviación típica de casi 4g.\n",
    "\n",
    "Acorde con Bayes, si tenemos información previa (el prior) podemos calcular la probabilidad a posteriori como:\n",
    "\\\\[\n",
    "P(\\theta|X)=\\frac{P(X|\\theta)·P_{apriori}(\\theta)}{P(X)}\n",
    "\\\\]\n",
    "\n",
    "Donde $X$ son los datos que tenemos y $\\theta$ son los parámetros que estimamos.\n",
    "\n",
    "Dados los pesos que hemos medido, \n",
    "¿cual es la probabilidad de que sigan una gaussiana de media 35 y desviación 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    "xdf<-data.frame(z=c(20,60))\n",
    "ggplot(xdf,aes(x=z))+stat_function(fun=dnorm,args = list(mean = 35, sd =4))+\n",
    "  geom_vline(xintercept = weights[1],color=\"blue\")+\n",
    "  geom_vline(xintercept = weights[2],color=\"blue\")+\n",
    "  geom_vline(xintercept = weights[3],color=\"blue\")+\n",
    "  stat_function(fun=dnorm,args = list(mean = mean(weights), sd =sd(weights)),color='gray')+\n",
    "  ylab(\"probabilidad\")+xlab(\"Peso [kg]\")+\n",
    "  theme_linedraw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (w in weights){\n",
    "    print(paste(\"La densidad de probabilidad de que pese\",w,\"es\",dnorm(w,mean=35,sd=4)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, la probabilidad de haber realizado una medida de 6kg es bastante baja. Es posible que se trate de un outlayer, un valor atípico, producto de un error en la medida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si seguimos adelante con el teorema de Bayes, lo que nos interesa es obtener el máximo a posteriori, maximizar $P(\\theta|X)$\n",
    "\n",
    "\\\\[\n",
    "\\hat {\\theta }\\in \\{{\\underset {\\theta \\in \\Theta }{\\operatorname {arg\\,max} }} P(\\theta|X)\\} =\\hat {\\theta }\\in \\{{\\underset {\\theta \\in \\Theta }{\\operatorname {arg\\,max} }} \\frac{P(X|\\theta)·P_{apriori}(\\theta)}{P(X)}\\}\n",
    "\\\\]\n",
    "\n",
    "Lo cual equivale a:\n",
    "\\\\[\n",
    "\\hat {\\theta }\\in \\{{\\underset {\\theta \\in \\Theta }{\\operatorname {arg\\,max} }} P(\\theta|X) \\}=\\{ {\\operatorname {arg\\,max} }P(X|\\theta)·P_{apriori}(\\theta)\\}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponemos que la desviación típica es la misma que la que hemos medido, pero desconocemos la media, el valor más probable del peso. Lo que se denomina el Máximo a Posteriori (MAP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newl<-function(theta){\n",
    "    mnkg=theta[1]    \n",
    "    mnkg_apriori=35\n",
    "    sdkg_apriori=4\n",
    "    -prod(sapply(weights,function(xi) (dnorm(xi,mean=mnkg,sd=sd(weights)))))*\n",
    "                                       dnorm(mnkg,mean=mnkg_apriori,sd=sdkg_apriori)\n",
    "}                \n",
    "                 \n",
    "o<-optim(c(35), newl, method =\"Brent\",lower = 10, upper = 60,)\n",
    "\n",
    "paste(\"La media óptima calculada mediante MAP es:\",o$par)\n",
    "paste(\"La media estimada es:\",mean(weights))                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    "xdf<-data.frame(z=c(20,60))\n",
    "ggplot(xdf,aes(x=z))+stat_function(fun=dnorm,args = list(mean = 35, sd =4))+\n",
    "  geom_vline(xintercept = weights[1],color=\"blue\")+\n",
    "  geom_vline(xintercept = weights[2],color=\"blue\")+\n",
    "  geom_vline(xintercept = weights[3],color=\"blue\")+\n",
    "  stat_function(fun=dnorm,args = list(mean = mean(weights), sd =sd(weights)),color='gray')+\n",
    "  stat_function(fun=dnorm,args = list(mean = o$par, sd =sd(weights)),color='red')+\n",
    "  geom_vline(xintercept = o$par,color=\"red\")+\n",
    "  ylab(\"probabilidad\")+xlab(\"Peso [kg]\")+\n",
    "  theme_linedraw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_weight<-40\n",
    "prb<-pnorm(max_weight,mean = o$par, sd =sd(weights),lower.tail=FALSE)\n",
    "paste(\"La probabilidad de que pese más de \",max_weight,'g es del ',round(prb*100),'%',sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt Text](https://media.giphy.com/media/ceHKRKMR6Ojao/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesianos vs Frecuentistas\n",
    "\n",
    "De obligada referencia: https://xkcd.com/1132/\n",
    "\n",
    "El MLE es igual al MAP cuando el prior es completamente desconocido, es decir, cuando es una uniforme.\n",
    "\n",
    "Características de aproximación Bayesiana:\n",
    "* La mayor parte de las veces sabemos como debería ser nuestra distribución.\n",
    "* Elegir mal el Prior puede tener consecuencias catastróficas.\n",
    "* Podemos obtener mejores resultados con menos muestras.\n",
    "\n",
    "Características de aproximación Frecuentista:\n",
    "* No necesitamos hacer ninguna suposición de los datos con lo que podemos evitar sesgos basados en prejuicios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test A/B\n",
    "\n",
    "Es un nombre utilizado realizar tests controlados con dos variantes A y B. Se puede utilizar por ejemplo para ver el cambio que se produce en una en una web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo test A/B\n",
    "\n",
    "Tenemos una web de compras. Sabemos que aproximadamente un 1% de los clientes que entran en la web acaban comprando algo. \n",
    "\n",
    "Queremos mejorar esto diseñando una nueva web y observando diferentes patrones en los usuarios que acceden.\n",
    "\n",
    "¿Que web es mejor la nueva o la original?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "set.seed(6)\n",
    "\n",
    "generateABdata<-function(N){\n",
    "    group<-factor(rbinom(N,size=1,p=0.5),label=c(\"Control\",\"New\"))\n",
    "    timespend<-rgamma(N,scale = 0.05,shape = 200)\n",
    "    timespend[group==\"New\"]<-rgamma(sum(group==\"New\"),scale = 0.1,shape = 110)\n",
    "    #timespend[group==\"New\"]<-rnorm(sum(group==\"New\"),mean = 12,sd = 5)\n",
    "\n",
    "    buy<-rbinom(N,size=1,p=0.01)\n",
    "    buy[group==\"New\"]<-rbinom(sum(group==\"New\"),size=1,p=0.015)    \n",
    "    buy<-factor(buy,label=c(\"NO\",\"YES\"))    \n",
    "    #timespend[buy==\"YES\" & group==\"New\"]<-rgamma(sum(buy==\"YES\" & group==\"New\"),scale = 0.1,shape = 100)\n",
    "    timespend[buy==\"YES\" & group==\"New\"]<-rnorm(sum(buy==\"YES\" & group==\"New\"),mean = 9,sd = 2)\n",
    "\n",
    "    data.frame(user_id=factor(1000+1:N),group,timespend,buy)\n",
    "}\n",
    "\n",
    "myweb<-generateABdata(1000)\n",
    "\n",
    "summary(myweb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero comprobamos si el tiempo gastado en la página ha cambiado o no respecto a si la web es de control o es la nueva versión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"Los datos del grupo de control se parecen a una gaussiana. p-valor:\",\n",
    "      shapiro.test(myweb$timespend[myweb$group==\"Control\"])$p.value)\n",
    "paste(\"Los datos del grupo nuevo se parecen a una gaussiana. p-valor:\",\n",
    "      shapiro.test(myweb$timespend[myweb$group==\"New\"])$p.value)\n",
    "\n",
    "\n",
    "t.test(x=myweb$timespend[myweb$group==\"Control\"],y=myweb$timespend[myweb$group==\"New\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que los usuarios pasan de media 11 minutos en la página nueva, mientras que en la de control pasan unos 10 minutos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos si el tiempo medio que pasa un usuario en la web se ve afectado si compra o no:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_users<-subset(myweb,buy==\"YES\")\n",
    "with(buy_users,t.test(x=timespend[group==\"Control\"],y=timespend[group==\"New\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que los usuarios que compran gastan una media de 9.2 minutos en la **nueva** web, mientras que gastan 9.68 en la **vieja**. Aunque el t-test nos dice que no hay evidencia estadística suficiente para asegurar que las dos medias realmente sean diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos que ocurre ahora con las compras, si han aumentado o no:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0<-sum(myweb$buy[myweb$group==\"Control\"]==\"YES\")\n",
    "t0<-sum(myweb$group==\"Control\")\n",
    "s1<-sum(myweb$buy[myweb$group==\"New\"]==\"YES\")\n",
    "t1<-sum(myweb$group==\"New\")\n",
    "\n",
    "m<-matrix(c(s0,s1,t1,t0),nrow = 2,dimnames=list(c(\"control\",\"nueva\"),c(\"compras\",\"visitas\")))\n",
    "m\n",
    "\n",
    "r1<-round(binom.test(m[1,1],m[1,2])$conf.int,4)\n",
    "r2<-round(binom.test(m[2,1],m[2,2])$conf.int,4)\n",
    "paste0(\"El ratio de compras en la web de control es:\",round(m[1,1]/m[1,2],4),\n",
    "       \" con un intervalo de confianza: [\",r1[1],\",\",r1[2],\"]\")\n",
    "paste0(\"El ratio de compras en la web nueva es:\",round(m[2,1]/m[2,2],4),\n",
    "       \" con un intervalo de confianza: [\",r2[1],\",\",r2[2],\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq.test(m)\n",
    "fisher.test(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto el test de fisher como el chi-cuadrado nos indican que no hay muestras sufientes para descartar la hipótesis nula. No podemos decir que la nueva web haya mejorado el ratio de clicks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si recogemos más datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myweb2<-generateABdata(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_users<-subset(myweb2,buy==\"YES\")\n",
    "with(buy_users,t.test(x=timespend[group==\"Control\"],y=timespend[group==\"New\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si somos capaces de ver que los usuarios que compran en la web nueva estan **menos tiempo**, eso puede indicar que es más fácil comprar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0<-sum(myweb2$buy[myweb2$group==\"Control\"]==\"YES\")\n",
    "t0<-sum(myweb2$group==\"Control\")\n",
    "s1<-sum(myweb2$buy[myweb2$group==\"New\"]==\"YES\")\n",
    "t1<-sum(myweb2$group==\"New\")\n",
    "\n",
    "m<-matrix(c(s0,s1,t1,t0),nrow = 2,dimnames=list(c(\"control\",\"nueva\"),c(\"compras\",\"visitas\")))\n",
    "m\n",
    "\n",
    "r1<-round(binom.test(m[1,1],m[1,2])$conf.int,4)\n",
    "r2<-round(binom.test(m[2,1],m[2,2])$conf.int,4)\n",
    "paste0(\"El ratio de compras en la web de control es:\",round(m[1,1]/m[1,2],4),\n",
    "       \" con un intervalo de confianza: [\",r1[1],\",\",r1[2],\"]\")\n",
    "paste0(\"El ratio de compras en la web nueva es:\",round(m[2,1]/m[2,2],4),\n",
    "       \" con un intervalo de confianza: [\",r2[1],\",\",r2[2],\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los ratio son más pequeños y apenas se solapan, parece que la web nueva mejora el ratio de compras. Algo que podemos comprobar con el test chi-cuadrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq.test(m)\n",
    "fisher.test(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test A/B con Bayes\n",
    "\n",
    "Recordemos el teorema de Bayes\n",
    "\\\\[\n",
    "P(\\theta|X)=\\frac{P(X|\\theta)·P_{apriori}(\\theta)}{P(X)}\n",
    "\\\\]\n",
    "\n",
    "Donde $X$ son los datos que tenemos y $\\theta$ son los parámetros que estimamos.\n",
    "\n",
    "\n",
    "En el caso de test A/B donde tratamos de ver la tasa de conversión (conversion rate) de dos grupos uno A y otro B.  Como estamos mirando si hay o no conversión esto se traduce en una distribución de Bernoulli. \n",
    "La distribución que tenemos es:\n",
    "\\\\[\n",
    "P(X|\\theta)=\\theta^{X=1}·(1-\\theta)^{1-X=1}\n",
    "\\\\]\n",
    "Donde $\\theta$ es el ratio de usuarios que se han convertido (que han comprado un producto) vs el total de usuarios: $\\theta=\\frac{n_s}{n_t}$.\n",
    "\n",
    "\n",
    "Al tener una función de distribución $P(X|\\theta)$, el prior, $P_{apriori}(\\theta)$ ha de ser una función Beta, para que $P(\\theta|X)$ también sea una función Beta y se cumple la siguiente propiedad:\n",
    "\\\\[\n",
    "Beta(\\alpha,\\beta) · Bernoulli \\left(\\theta=\\frac{a}{a+b}\\right) = Beta(\\alpha + a,\\beta+b)\n",
    "\\\\]\n",
    "\n",
    "\n",
    "Recordemos que en una función Beta los estimadoes son:\n",
    "\n",
    "Estimadores **media** ($\\mu$) y **varianza** ($\\sigma^2$):\n",
    "\\\\[\n",
    "\\mu= \\frac{\\alpha}{\\alpha + \\beta} \\qquad\n",
    "\\sigma^2= \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}\n",
    "\\\\]\n",
    "La moda sería:\n",
    "\\\\[\n",
    "moda = \\frac{\\alpha-1}{\\alpha + \\beta -2}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos sacados de:\n",
    "https://www.gamasutra.com/blogs/ViktorGregor/20181105/328404/Its_time_to_rethink_AB_testing.php#comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_t <- 1000\n",
    "na_s <- 197\n",
    "nb_t <- 1000\n",
    "nb_s <- 230\n",
    "m <- matrix(c(na_s,na_t,nb_s,nb_t), byrow = T,nrow = 2,\n",
    "            dimnames=list(c(\"control\",\"nuevo\"),c(\"exitos\",\"intentos\")))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versión frecuentista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentaje de la media de conversión de cada grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_margin <- round(binom.test(na_s,na_t)$conf.int,3)\n",
    "pb_margin <- round(binom.test(nb_s,nb_t)$conf.int,3)\n",
    "\n",
    "matrix(c(pa_margin,pb_margin)*100,nrow=2,dimnames=list(c(\"control\",\"nuevo\"),c(\"5%\",\"95%\")), byrow = T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Margen de confianza del del 95%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq.test(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher.test(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versión Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_a <- 2\n",
    "prior_b <- 8\n",
    "\n",
    "x <- seq(0,1,by=0.01)\n",
    "p <- dbeta(x,prior_a,prior_b)\n",
    "plot(x, p,t=\"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La media sería\n",
    "sum(x*p)*(x[2]-x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "x <- seq(0,0.3, by = 0.001)\n",
    "\n",
    "p1 <- dbeta(x,prior_a+na_s,prior_b+(na_t-na_s))\n",
    "p2 <- dbeta(x,prior_b+nb_s,prior_b+(nb_t-nb_s))\n",
    "\n",
    "df<-data.frame(x=x*100,prob=c(p1,p2),name=c(rep(\"control\",length(x)),rep(\"nuevo\",length(x))))\n",
    "ggplot(data=df,aes(x=x,y=prob,color=name))+geom_line()+xlim(16,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentaje de la media de conversión de cada grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_a <- sum(x*p1)*(x[2]-x[1])\n",
    "cr_b <- sum(x*p2)*(x[2]-x[1])          \n",
    "matrix(c(cr_a,cr_b)*100,nrow=1,dimnames=list(c(\"conversión\"),c(\"control\",\"nuevo\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Margen de confianza del del 95%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_margin <- qbeta(c(0.025,0.0975),prior_a+na_s,prior_b+(na_t-na_s))\n",
    "pb_margin <- qbeta(c(0.025,0.0975),prior_b+nb_s,prior_b+(nb_t-nb_s))\n",
    "\n",
    "matrix(c(pa_margin,pb_margin)*100,nrow=2,dimnames=list(c(\"control\",\"nuevo\"),c(\"5%\",\"95%\")) , byrow=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a simular por montercarlo la diferencia entre los dos grupos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N <- 1000000\n",
    "r1 <- rbeta(N,prior_a+na_s,prior_b+(na_t-na_s))\n",
    "r2 <- rbeta(N,prior_a+nb_s,prior_b+(nb_t-nb_s))\n",
    "diff_df<-data.frame(x=(r2-r1))\n",
    "ggplot(data=diff_df,aes(x*100))+geom_density(color=\"blue\")+geom_vline(xintercept =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad de que mejore la **nueva** web es de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(sum(diff_df$x>0)/nrow(diff_df),3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mejora esperada si la *nueva* es realmente mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(diff_df$x[diff_df$x>0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La empeora esperada si la **nueva** es realmente peor es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(diff_df$x[diff_df$x<=0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes aplicado a StarWars\n",
    "\n",
    "https://www.countbayesie.com/blog/2015/2/18/hans-solo-and-bayesian-priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
